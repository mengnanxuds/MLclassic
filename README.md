# MLclassic

This repository contains implementations of fundamental classic machine learning algorithms in Python, organized for ease of learning and practical use. Each algorithm is accompanied by detailed explanations, clean code, and interactive Jupyter Notebooks demonstrating their functionality using real-world datasets. Whether youâ€™re a beginner or an experienced practitioner, this repo serves as a comprehensive resource for understanding and applying classic ML techniques such as regression, classification, clustering, ensemble methods, and dimensionality reduction.

### Key Features:
	â€¢	Modular and well-documented code.
	â€¢	Interactive Jupyter Notebooks with visualizations.
	â€¢	Small datasets for hands-on experimentation.
	â€¢	Utility functions for metrics, plotting, and data loading.

Perfect for students, developers, and data enthusiasts to strengthen their foundation in machine learning. ðŸš€


### Highlights of the Repo:
	1.	Modularity: Each algorithm has a dedicated folder with self-contained code, explanations, and examples.
	2.	Documentation: Every folder has a README.md explaining the algorithm in detail (theory + code).
	3.	Reusability: Utility functions and example datasets make it easy to test and extend.
	4.	Jupyter Notebooks: Visual explanations and hands-on demonstrations for each algorithm.
	5.	Performance Comparison: A separate notebook to benchmark the algorithms.


 ### Repo Directory Structure

 classic-ml-algorithms/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ regression/
â”‚   â”‚   â”œâ”€â”€ linear_regression/
â”‚   â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ logistic_regression/
â”‚   â”‚       â”œâ”€â”€ logistic_regression.py
â”‚   â”‚       â”œâ”€â”€ logistic_regression.ipynb
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ decision_tree/
â”‚   â”‚   â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”‚   â”‚   â”œâ”€â”€ decision_tree.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ naive_bayes/
â”‚   â”‚       â”œâ”€â”€ naive_bayes.py
â”‚   â”‚       â”œâ”€â”€ naive_bayes.ipynb
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â”œâ”€â”€ kmeans/
â”‚   â”‚   â”‚   â”œâ”€â”€ kmeans.py
â”‚   â”‚   â”‚   â”œâ”€â”€ kmeans.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ hierarchical_clustering/
â”‚   â”‚       â”œâ”€â”€ hierarchical_clustering.py
â”‚   â”‚       â”œâ”€â”€ hierarchical_clustering.ipynb
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ dimensionality_reduction/
â”‚   â”‚   â”œâ”€â”€ pca/
â”‚   â”‚   â”‚   â”œâ”€â”€ pca.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pca.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ lda/
â”‚   â”‚       â”œâ”€â”€ lda.py
â”‚   â”‚       â”œâ”€â”€ lda.ipynb
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ ensemble_methods/
â”‚   â”‚   â”œâ”€â”€ bagging/
â”‚   â”‚   â”‚   â”œâ”€â”€ bagging.py
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ boosting/
â”‚   â”‚   â”‚   â”œâ”€â”€ boosting.py
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ random_forest/
â”‚   â”‚       â”œâ”€â”€ random_forest.py
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ support_vector_machines/
â”‚       â”œâ”€â”€ svm.py
â”‚       â”œâ”€â”€ svm.ipynb
â”‚       â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ iris.csv
â”‚   â”œâ”€â”€ breast_cancer.csv
â”‚   â”œâ”€â”€ wine.csv
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ plot_utils.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚
â””â”€â”€ notebooks/
    â”œâ”€â”€ overview_of_algorithms.ipynb
    â”œâ”€â”€ performance_comparison.ipynb
    â”œâ”€â”€ README.md





    